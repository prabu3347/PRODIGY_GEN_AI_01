# PRODIGY_GenAI_01

**Task 1 â€“ Text Generation with GPT-2**  
**Internship:** Generative AI â€“ Prodigy Infotech

---

## ğŸ“ Description

This task implements **text generation** using the `transformers` library. A pre-trained GPT-2 model is used to generate coherent and context-aware text based on a given input prompt. The model can mimic natural language and produce continuations that align with the context of the seed text.

---

## ğŸ› ï¸ Tools & Technologies

- Python  
- Hugging Face Transformers  
- PyTorch  
- Google Colab / VS Code  

---

## ğŸ“ Files

- `gpt2_text_generator.ipynb`: Full implementation and result

---

## âœ… Outcome

Successfully generated multiple text outputs from custom input prompts using GPT-2. The model demonstrated coherent sentence completions, fulfilling the objective of Task 1 of the internship.

---

ğŸ”´ Submitted for: Prodigy Infotech â€“ Generative AI Internship
