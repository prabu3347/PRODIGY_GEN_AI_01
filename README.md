# PRODIGY_GenAI_01

**Task 1 – Text Generation with GPT-2**  
**Internship:** Generative AI – Prodigy Infotech

---

## 📝 Description

This task implements **text generation** using the `transformers` library. A pre-trained GPT-2 model is used to generate coherent and context-aware text based on a given input prompt. The model can mimic natural language and produce continuations that align with the context of the seed text.

---

## 🛠️ Tools & Technologies

- Python  
- Hugging Face Transformers  
- PyTorch  
- Google Colab / VS Code  

---

## 📁 Files

- `gpt2_text_generator.ipynb`: Full implementation and result

---

## ✅ Outcome

Successfully generated multiple text outputs from custom input prompts using GPT-2. The model demonstrated coherent sentence completions, fulfilling the objective of Task 1 of the internship.

---

🔴 Submitted for: Prodigy Infotech – Generative AI Internship
